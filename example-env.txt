# API and Endpoint Configuration
LLM_API_BASE_URL=http://localhost:11434/v1
LLM_API_KEY=api-key
SCREENPIPE_PORT=3030
IS_DOCKER=False

# Model Configuration
BAML_MODEL=qwen2.5-coder:latest
TOOL_MODEL=gpt-4o-mini
RESPONSE_MODEL=qwen2.5:3b

NATIVE_TOOL_CALLING=true
GET_RESPONSE=true

# Pipeline Settings
DEFAULT_UTC_OFFSET=-7
