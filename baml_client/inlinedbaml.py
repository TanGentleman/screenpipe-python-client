###############################################################################
#
#  Welcome to Baml! To use this generated code, please run the following:
#
#  $ pip install baml
#
###############################################################################

# This file was generated by BAML: please do not edit it. Instead, edit the
# BAML files and re-generate this code.
#
# ruff: noqa: E501,F401
# flake8: noqa: E501,F401
# pylint: disable=unused-import,line-too-long
# fmt: off

file_map = {
    
    "clients.baml": "// Learn more about clients at https://docs.boundaryml.com/docs/snippets/clients/overview\n\nclient<llm> CustomLlama {\n  provider openai\n  options {\n    model \"sambanova-llama-8b\"\n    base_url \"http://localhost:4000/v1\"\n    api_key env.LLM_API_KEY\n  }\n}\n\nclient<llm> SmallNova {\n  provider openai\n  options {\n    model \"sambanova-llama-3b\"\n    base_url \"http://localhost:4000/v1\"\n    api_key env.LLM_API_KEY\n  }\n}\n\nclient<llm> GeminiFlash {\n  provider openai\n  options {\n    model \"openrouter/google/gemini-flash-1.5-8b\"\n    base_url \"http://localhost:4000/v1\"\n    api_key env.LLM_API_KEY\n  }\n}\n\n\nclient<llm> CustomGPT4o {\n  provider openai\n  options {\n    model \"gpt-4o\"\n    api_key env.OPENAI_API_KEY\n  }\n}\n\nclient<llm> CustomGPT4oMini {\n  provider openai\n  retry_policy Exponential\n  options {\n    model \"gpt-4o-mini\"\n    api_key env.OPENAI_API_KEY\n  }\n}\n\nclient<llm> CustomSonnet {\n  provider anthropic\n  options {\n    model \"claude-3-5-sonnet-20241022\"\n    api_key env.ANTHROPIC_API_KEY\n  }\n}\n\n\nclient<llm> CustomHaiku {\n  provider anthropic\n  retry_policy Constant\n  options {\n    model \"claude-3-haiku-20240307\"\n    api_key env.ANTHROPIC_API_KEY\n  }\n}\n\n// https://docs.boundaryml.com/docs/snippets/clients/round-robin\nclient<llm> CustomFast {\n  provider round-robin\n  options {\n    // This will alternate between the two clients\n    strategy [CustomGPT4oMini, CustomHaiku]\n  }\n}\n\n// https://docs.boundaryml.com/docs/snippets/clients/fallback\nclient<llm> OpenaiFallback {\n  provider fallback\n  options {\n    // This will try the clients in order until one succeeds\n    strategy [CustomGPT4oMini, CustomGPT4oMini]\n  }\n}\n\n// https://docs.boundaryml.com/docs/snippets/clients/retry\nretry_policy Constant {\n  max_retries 3\n  // Strategy is optional\n  strategy {\n    type constant_delay\n    delay_ms 200\n  }\n}\n\nretry_policy Exponential {\n  max_retries 2\n  // Strategy is optional\n  strategy {\n    type exponential_backoff\n    delay_ms 300\n    mutliplier 1.5\n    max_delay_ms 10000\n  }\n}",
    "generators.baml": "// This helps use auto generate libraries you can use in the language of\n// your choice. You can have multiple generators if you use multiple languages.\n// Just ensure that the output_dir is different for each generator.\ngenerator target {\n    // Valid values: \"python/pydantic\", \"typescript\", \"ruby/sorbet\", \"rest/openapi\"\n    output_type \"python/pydantic\"\n\n    // Where the generated code will be saved (relative to baml_src/)\n    output_dir \"../\"\n\n    // The version of the BAML package you have installed (e.g. same version as your baml-py or @boundaryml/baml).\n    // The BAML VSCode extension version should also match this version.\n    version \"0.67.0\"\n\n    // Valid values: \"sync\", \"async\"\n    // This controls what `b.FunctionName()` will be (sync or async).\n    default_client_mode sync\n}\n",
    "search.baml": "// Defining the search parameters data model\nclass SearchParameters {\n  limit int\n  content_type string\n  search_substring string?\n  start_time string?\n  end_time string?\n  app_name string?\n}\n\n// Inject a list of \"system\" or \"user\" messages into the prompt.\n// template_string PrintMessages(messages: Message[]) #\"\n//   {% for m in messages %}\n//     {{ _.role(m.role) }}\n//     {{ m.message }}\n//   {% endfor %}\n// \"#\n\n// function ClassifyConversation(messages: Message[]) -> Category[] {\n//   client GPT4Turbo\n//   prompt #\"\n//     Classify this conversation:\n//     {{ PrintMessages(messages) }}\n\n//     Use the following categories:\n//     {{ ctx.output_format}}\n//   \"#\n// }\n\n// Create a function to validate and process search parameters\nfunction ConstructSearchParameters(query: string, current_iso_timestamp: string) -> SearchParameters {\n  client GeminiFlash\n  prompt #\"\n    {{ _.role(\"system\") }} \n    Create search parameters to filter database content. Only include search_substring or time parameters if specified.\n\n    Ensure the following rules are met:\n    - limit must be between 1 and 100. defaults to 5 if not specified.\n    - content_type must be one of: \"ocr\", \"audio\", \"all\"\n    - time values should be null or in ISO format\n\n    {{ ctx.output_format }}\n\n    {{ _.role(\"user\") }}\n    QUERY: {{ query }}\n    - The current time is {{ current_iso_timestamp }}\n  \"#\n}\n\n// Test the function with sample search parameters\ntest basic_search {\n  functions [ConstructSearchParameters]\n  args {\n    query #\"\n      I want to search for all ocr content from the last 24 hours.\n    \"#\n    current_iso_timestamp #\"2024-11-12T12:00:00Z\"#\n  }\n} ",
}

def get_baml_files():
    return file_map